{"meta":{"title":"AUTISMTHROW'S BLOG","subtitle":null,"description":null,"author":"AutismThrow","url":"http://yoursite.com","root":"/"},"pages":[{"title":"archive","date":"2019-05-14T03:04:47.000Z","updated":"2019-05-14T03:04:47.228Z","comments":true,"path":"archive/index.html","permalink":"http://yoursite.com/archive/index.html","excerpt":"","text":""},{"title":"about","date":"2019-05-14T02:26:43.000Z","updated":"2019-05-14T02:28:41.406Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-05-14T03:14:36.000Z","updated":"2019-05-14T03:14:36.233Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"friends","date":"2019-05-14T03:10:21.000Z","updated":"2019-05-14T03:10:21.820Z","comments":true,"path":"friends/index.html","permalink":"http://yoursite.com/friends/index.html","excerpt":"","text":""},{"title":"projects","date":"2019-05-14T04:41:25.000Z","updated":"2019-05-14T04:41:25.946Z","comments":true,"path":"projects/index.html","permalink":"http://yoursite.com/projects/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-05-14T03:14:14.000Z","updated":"2019-05-14T03:14:14.340Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"kafka原理","slug":"kafka原理","date":"2019-05-30T14:17:50.465Z","updated":"2019-05-30T15:16:58.218Z","comments":true,"path":"2019/05/30/kafka原理/","link":"","permalink":"http://yoursite.com/2019/05/30/kafka原理/","excerpt":"kafka原理","text":"kafka原理 一、为什么需要消息系统 解耦： 允许你独立的拓展或修改两边的处理过程，只要确保他们遵守同样的接口约束 冗余： 消息队列把数据进行持久啊知道他们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的“插入-获取-删除”范式中，在把一个消息从消息队列中删除之前，需要捏处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。 扩展性： 因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可 灵活性&amp;峰值处理能力： 在访问量剧增的情况下，应用仍然需要继续发挥作用，当时这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。 可恢复性： 系统的一部分组建失效时，不会影响到整个系统。效力对了降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。 顺序保证： 在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且保证数据会按照特定的顺序来处理。（kafka保证一个Partition内的消息的有序性） 缓冲： 有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。 异步通信： 很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后子啊需要的时候再去处理它们。 二、相关概念 producer： 消息生产者，发布消息到Kafka集群的终端或服务。 broker： kafka集群中包含的服务器。 topic： 每条发布到kafka集群的消息属于的类别，即Kafka是面向topic的。 partition： partition是物理上的概念，每个topic包含一个或多个partition。Kafka分配的单位是partition。 consumer： 从Kafka集群中消费消息的终端或服务 Consumer group： high-level consumer API中，每个consumer都属于一个consumer group，每条消息只能被consumer group中的一个consumer消费，但可以被多个consumer group消费。 replica： partition的副本，保障partition的高可用。 leader： replica中的一个角色，，producer和consumer只跟leader交互。 follower： replica中的一个角色，从leader中复制数据。 controller： Kafka集群中的一个服务器，用来进行leader election以及各种failover。 zokeeper： Kafka通过zookeeper来存储集群的meta信息。 三、producer发布消息3.1 写入方式producer采用push模式将消息发布到broker，每条消息都被append到partition中，属于顺序写入磁盘（顺序写磁盘效率比随即写内存要高，保障kafka吞吐率）。 3.2 消息路由producer发送消息到broker时，会根据分区算法选择将其存储到哪一个partition。其路由机制为： 1231. 指定了partition，则直接使用；2. 未指定partition但直到那个key，通过对key的value进行hash选出一个partition3. partition和key都为指定，使用轮询选出一个partition。 java客服端分区源码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//创建消息实例public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value) &#123; if (topic == null) throw new IllegalArgumentException(\"Topic cannot be null\"); if (timestamp != null &amp;&amp; timestamp &lt; 0) throw new IllegalArgumentException(\"Invalid timestamp \" + timestamp); this.topic = topic; this.partition = partition; this.key = key; this.value = value; this.timestamp = timestamp;&#125;//计算 patition，如果指定了 patition 则直接使用，否则使用 key 计算private int partition(ProducerRecord&lt;K, V&gt; record, byte[] serializedKey , byte[] serializedValue, Cluster cluster) &#123; Integer partition = record.partition(); if (partition != null) &#123; List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(record.topic()); int lastPartition = partitions.size() - 1; if (partition &lt; 0 || partition &gt; lastPartition) &#123; throw new IllegalArgumentException(String.format(\"Invalid partition given with record: %d is not in the range [0...%d].\", partition, lastPartition)); &#125; return partition; &#125; return this.partitioner.partition(record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);&#125;// 使用 key 选取 patitionpublic int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) &#123; List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic); int numPartitions = partitions.size(); if (keyBytes == null) &#123; int nextValue = counter.getAndIncrement(); List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic); if (availablePartitions.size() &gt; 0) &#123; int part = DefaultPartitioner.toPositive(nextValue) % availablePartitions.size(); return availablePartitions.get(part).partition(); &#125; else &#123; return DefaultPartitioner.toPositive(nextValue) % numPartitions; &#125; &#125; else &#123; //对 keyBytes 进行 hash 选出一个 patition return DefaultPartitioner.toPositive(Utils.murmur2(keyBytes)) % numPartitions; &#125;&#125; 3.3 写入流程 流程总结： 123451. producer 先从 zookeeper 的 &quot;/brokers/.../state&quot; 节点找到该 partition 的 leader2. producer 将消息发送给该 leader3. leader 将消息写入本地 log4. followers 从 leader pull 消息，写入本地 log 后 leader 发送 ACK5. leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK 3.4 发送消息发送消息主要有三种方式： fire-and-forget（发送并忘记）： 不关注消息是否成功到达，大部分情况下没消息会成功送达至broker。但是还是会存在消息丢失的情况 1234567ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;String, String&gt;(\"CustomerCountry\", \"Precision Products\", \"France\");try &#123; producer.send(record);&#125; catch (Exception e) &#123; e.printStackTrace();&#125; Synchronous send（同步发送）： 调用send方法后返回一个Future对象，在调用get()方法会等待直到结果返回，根据返回的结果可以判断是都发送成功 1234567ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;String, String&gt;(\"CustomerCountry\", \"Precision Products\", \"France\");try &#123; producer.send(record).get();&#125; catch (Exception e) &#123; e.printStackTrace();&#125; Aysnchronous send（异步发送）： 我们调用send()方法，并指定一个回调函数，服务器在返回响应时调用该函数。 12345678910class DemoProducerCallback implements Callback &#123; @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) &#123; if (e != null) &#123; e.printStackTrace(); &#125; &#125;&#125; producer.send(record, new DemoProducerCallback()); 要使用callback函数，先要实现Callback接口，该接口只有一个onCompletion方法。如果发送异常，onCompletion的参数Exception e会为非空 四、broker 保存消息4.1 存储方式物理上把topic分成一个或多个partition（对应server.properties中的num.partition=3 配置），每个partiton物理上对应一个文件下（该文件夹存储该partition的所有消息和索引文件）。 4.2 存储策略无论消息是否被消费，kafka都会保留所有消息。有两种策略可以删除旧数据： 121. 基于时间：log.retention.hours=1682. 基于大小：log.retention.bytes=1073741824 kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高Kafka性能无关。 4.3 topic 创建与删除4.3.1 topic创建创建图例： 流程说明： 123451. controller 在 ZooKeeper 的 /brokers/topics 节点上注册 watcher，当 topic 被创建，则 controller 会通过 watch 得到该 topic 的 partition/replica 分配。2. controller从 /brokers/ids 读取当前所有可用的 broker 列表，对于 set_p 中的每一个 partition： 2.1 从分配给该 partition 的所有 replica（称为AR）中任选一个可用的 broker 作为新的 leader，并将AR设置为新的 ISR 2.2 将新的 leader 和 ISR 写入 /brokers/topics/[topic]/partitions/[partition]/state3. controller 通过 RPC 向相关的 broker 发送 LeaderAndISRRequest。 4.3.2 topic删除删除图例： 流程说明： 121. controller 在 zooKeeper 的 /brokers/topics 节点上注册 watcher，当 topic 被删除，则 controller 会通过 watch 得到该 topic 的 partition/replica 分配。2. 若 delete.topic.enable=false，结束；否则 controller 注册在 /admin/delete_topics 上的 watch 被 fire，controller 通过回调向对应的 broker 发送 StopReplicaRequest。","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2019-05-13T10:16:34.899Z","updated":"2019-05-31T03:36:54.740Z","comments":true,"path":"2019/05/13/hello-world/","link":"","permalink":"http://yoursite.com/2019/05/13/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}